{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# https://github.com/higgsfield/RL-Adventure/blob/master/1.dqn.ipynb\n",
    "# DQN without a frozen target network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import yaml\n",
    "import datetime\n",
    "\n",
    "# from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "%load_ext memory_profiler\n",
    "%load_ext line_profiler\n",
    "%load_ext heat\n",
    "%load_ext snakeviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "# %reload_ext tensorboard\n",
    "# %tensorboard --port=9706 --logdir ./runs\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXPERIMENT:  base_config \tSEED:  324267 writer_dir:  ./runs/base_config_324267_20190819-084735\n"
     ]
    }
   ],
   "source": [
    "# experiment_no = 'exp_1'\n",
    "experiment_no = 'base_config'\n",
    "\n",
    "seed_value = 324267 # sys.argv[1]\n",
    "\n",
    "# Writer will output to ./runs/ directory by default\n",
    "writer_dir = './runs/' + experiment_no + '_' + str(seed_value) + '_' + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "writer = SummaryWriter(writer_dir)\n",
    "print(\"EXPERIMENT: \", experiment_no, \"\\tSEED: \", seed_value, \"writer_dir: \", writer_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# FROM CONFIG FILE\n",
    "config_path =  './' + experiment_no + '.yaml' # sys.argv[2]\n",
    "config = yaml.safe_load(open(config_path,'r'))\n",
    "  \n",
    "import math\n",
    "import os \n",
    "import random \n",
    "import numpy as np \n",
    "import tensorflow as tf \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.autograd as autograd \n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "os.environ['PYTHONHASHSEED']=str(seed_value) \n",
    "random.seed(seed_value) \n",
    "np.random.seed(seed_value) \n",
    "tf.random.set_seed(seed_value)\n",
    "torch.manual_seed(seed_value)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "# CartPole-v0 Environment\n",
    "env_id = \"CartPole-v0\"\n",
    "env = gym.make(env_id)\n",
    "env.seed(seed_value);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USE_GPU = config['USE_GPU']\n",
    "\n",
    "# # Use CUDA\n",
    "# USE_CUDA = torch.cuda.is_available() and USE_GPU\n",
    "\n",
    "# if USE_CUDA:\n",
    "#     torch.cuda.manual_seed(seed_value)\n",
    "#     device = torch.device('cuda')\n",
    "# else:\n",
    "#     device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REPLAY BUFFER\n",
    "\n",
    "from collections import deque\n",
    "\n",
    "class ReplayBuffer(object):\n",
    "    def __init__(self, capacity):\n",
    "        self.buffer = deque(maxlen=capacity)\n",
    "    \n",
    "    def push(self, state, action, reward, next_state, done):\n",
    "        state      = np.expand_dims(state, 0)\n",
    "        next_state = np.expand_dims(next_state, 0)\n",
    "            \n",
    "        self.buffer.append((state, action, reward, next_state, done))\n",
    "    \n",
    "    def sample(self, batch_size):\n",
    "        state, action, reward, next_state, done = zip(*random.sample(self.buffer, batch_size))\n",
    "        return np.concatenate(state), action, reward, np.concatenate(next_state), done\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class D1QN(nn.Module): #base model\n",
    "    def __init__(self, num_inputs, num_actions, HIDDEN_LAYER_WIDTH):\n",
    "        super(D1QN, self).__init__()\n",
    "        \n",
    "        self.action_dim = num_actions\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(num_inputs, HIDDEN_LAYER_WIDTH),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(HIDDEN_LAYER_WIDTH, HIDDEN_LAYER_WIDTH),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(HIDDEN_LAYER_WIDTH, num_actions)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "    \n",
    "    def act(self, state, epsilon):\n",
    "        with torch.no_grad():\n",
    "            if random.random() > epsilon:\n",
    "                state   = torch.tensor(state, dtype=torch.float32).unsqueeze(0)\n",
    "                q_value = self.forward(state)\n",
    "                action  = q_value.max(1)[1].data[0].item()\n",
    "            else:\n",
    "                action = random.randrange(self.action_dim)\n",
    "        return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# e-greedy exploration\n",
    "\n",
    "epsilon_start = config['EPSILON_START']\n",
    "epsilon_final = config['EPSILON_FINAL']\n",
    "epsilon_decay = config['EPSILON_DECAY']\n",
    "\n",
    "epsilon_by_frame = lambda frame_idx: epsilon_final + (epsilon_start - epsilon_final) * math.exp(-1. * frame_idx / epsilon_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot([epsilon_by_frame(i) for i in range(10000)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D1QN(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=4, out_features=128, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=128, out_features=2, bias=True)\n",
      "  )\n",
      ")\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1                  [32, 128]             640\n",
      "              ReLU-2                  [32, 128]               0\n",
      "            Linear-3                  [32, 128]          16,512\n",
      "              ReLU-4                  [32, 128]               0\n",
      "            Linear-5                    [32, 2]             258\n",
      "================================================================\n",
      "Total params: 17,410\n",
      "Trainable params: 17,410\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.13\n",
      "Params size (MB): 0.07\n",
      "Estimated Total Size (MB): 0.19\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# MODEL\n",
    "if (config['MODEL_NAME']=='D1QN'):\n",
    "    model = D1QN(env.observation_space.shape[0], \n",
    "                 env.action_space.n,\n",
    "                 config['HIDDEN_LAYER_WIDTH'])\n",
    "else: #default model is DQN class\n",
    "    model = D1QN(env.observation_space.shape[0], \n",
    "                 env.action_space.n,\n",
    "                 config['HIDDEN_LAYER_WIDTH'])    \n",
    "\n",
    "# model = model.to(device)\n",
    "print(model)\n",
    "summary(model, \n",
    "        input_size=(env.observation_space.shape[0],),\n",
    "        batch_size=config['BATCH_SIZE'], \n",
    "        device='cpu' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIMIZER\n",
    "if (config['OPTIMIZER']=='Adam'):\n",
    "    optimizer = optim.Adam(model.parameters(), \n",
    "                           lr=config['LEARNING_RATE'])\n",
    "elif (config['OPTIMIZER']=='SGD'):\n",
    "    optimizer = optim.SGD(model.parameters(), \n",
    "                           lr=config['LEARNING_RATE'])\n",
    "else: #default optimizer is Adam\n",
    "    optimizer = optim.Adam(model.parameters(), \n",
    "                           lr=config['LEARNING_RATE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CRITERION\n",
    "if (config['CRITERION']=='MSE'):\n",
    "    criterion = nn.MSELoss()\n",
    "elif (config['CRITERION']=='HUBER'):\n",
    "    criterion = nn.SmoothL1Loss()\n",
    "else: #default criterion is MSELoss\n",
    "    criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REPLAY BUFFER\n",
    "replay_buffer = ReplayBuffer(capacity=config['REPLAY_BUFFER_SIZE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_td_loss(batch_size):\n",
    "    state, action, reward, next_state, done = replay_buffer.sample(batch_size)\n",
    "    \n",
    "    state      = torch.tensor(np.float32(state)      ,dtype=torch.float32)\n",
    "    next_state = torch.tensor(np.float32(next_state) ,dtype=torch.float32, requires_grad=False)\n",
    "    action     = torch.tensor(action                ,dtype=torch.long)\n",
    "    reward     = torch.tensor(reward                ,dtype=torch.float32)\n",
    "    done       = torch.tensor(done                  ,dtype=torch.float32)\n",
    "#     state      = torch.tensor(np.float32(state)      ,dtype=torch.float32).to(device)\n",
    "#     next_state = torch.tensor(np.float32(next_state) ,dtype=torch.float32, requires_grad=False).to(device)\n",
    "#     action     = torch.tensor(action                ,dtype=torch.long).to(device)\n",
    "#     reward     = torch.tensor(reward                ,dtype=torch.float32).to(device)\n",
    "#     done       = torch.tensor(done                  ,dtype=torch.float32).to(device)\n",
    "\n",
    "    with torch.autograd.profiler.profile(use_cuda=config['USE_GPU']) as prof:\n",
    "        q_values      = model(state)\n",
    "        next_q_values = model(next_state)\n",
    "\n",
    "    q_value          = q_values.gather(1, action.unsqueeze(1)).squeeze(1)\n",
    "    next_q_value     = next_q_values.max(1)[0]\n",
    "    expected_q_value = reward + gamma * next_q_value * (1 - done)\n",
    "\n",
    "    loss = criterion(q_value, expected_q_value)\n",
    "       \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(frame_idx, rewards, losses):\n",
    "    clear_output(True)\n",
    "    plt.figure(figsize=(20,5))\n",
    "    plt.subplot(131)\n",
    "    plt.title('frame %s. reward: %s' % (frame_idx, np.mean(rewards[-10:])))\n",
    "    plt.plot(rewards)\n",
    "    plt.subplot(132)\n",
    "    plt.title('loss')\n",
    "    plt.plot(losses)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6min 55s, sys: 4min 41s, total: 11min 37s\n",
      "Wall time: 3min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# %%memit\n",
    "\n",
    "# Training\n",
    "num_frames = config['TIMESTEPS']\n",
    "batch_size = config['BATCH_SIZE']\n",
    "gamma      = config['GAMMA']\n",
    "\n",
    "losses = []\n",
    "all_rewards = []\n",
    "episode_reward = 0\n",
    "\n",
    "state = env.reset()\n",
    "\n",
    "for frame_idx in range(1, num_frames + 1):\n",
    "    epsilon = epsilon_by_frame(frame_idx)\n",
    "    with torch.autograd.profiler.profile(use_cuda=config['USE_GPU']) as prof:\n",
    "        action = model.act(state, epsilon)\n",
    "    \n",
    "    next_state, reward, done, _ = env.step(action)\n",
    "    replay_buffer.push(state, action, reward, next_state, done)\n",
    "    \n",
    "    state = next_state\n",
    "    episode_reward += reward\n",
    "    \n",
    "    if done:\n",
    "        writer.add_scalar('episode_reward', episode_reward, global_step=frame_idx)\n",
    "        state = env.reset()\n",
    "        all_rewards.append(episode_reward)\n",
    "        episode_reward = 0\n",
    "        \n",
    "    if len(replay_buffer) > batch_size:\n",
    "        loss = compute_td_loss(batch_size)\n",
    "        losses.append(loss.item())\n",
    "                \n",
    "\n",
    "        writer.add_scalar('loss', loss.item(), global_step=frame_idx)\n",
    "        writer.add_scalar('epsilon', epsilon, global_step=frame_idx)\n",
    "        for name, param in model.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                writer.add_histogram(name, param.data, global_step=frame_idx)\n",
    "        \n",
    "#     if frame_idx % 200 == 0:\n",
    "#         plot(frame_idx, all_rewards, losses)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  -----------------------------------  \n",
      "Name                     Self CPU total %  Self CPU total   CPU total %      CPU total        CPU time avg     CUDA total %     CUDA total       CUDA time avg    Number of Calls  Input Shapes                         \n",
      "-----------------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  -----------------------------------  \n",
      "to                       7.95%            9.386us          7.95%            9.386us          9.386us          NaN              0.000us          0.000us          1                []                                   \n",
      "empty                    2.11%            2.490us          2.11%            2.490us          2.490us          NaN              0.000us          0.000us          1                []                                   \n",
      "detach_                  0.33%            0.384us          0.33%            0.384us          0.384us          NaN              0.000us          0.000us          1                []                                   \n",
      "unsqueeze                3.20%            3.779us          3.20%            3.779us          3.779us          NaN              0.000us          0.000us          1                []                                   \n",
      "unsigned short           2.37%            2.804us          2.37%            2.804us          2.804us          NaN              0.000us          0.000us          1                []                                   \n",
      "addmm                    12.00%           14.172us         12.00%           14.172us         14.172us         NaN              0.000us          0.000us          1                []                                   \n",
      "relu                     5.62%            6.633us          5.62%            6.633us          6.633us          NaN              0.000us          0.000us          1                []                                   \n",
      "unsigned short           2.00%            2.364us          2.00%            2.364us          2.364us          NaN              0.000us          0.000us          1                []                                   \n",
      "addmm                    24.77%           29.254us         24.77%           29.254us         29.254us         NaN              0.000us          0.000us          1                []                                   \n",
      "relu                     4.86%            5.738us          4.86%            5.738us          5.738us          NaN              0.000us          0.000us          1                []                                   \n",
      "unsigned short           1.95%            2.298us          1.95%            2.298us          2.298us          NaN              0.000us          0.000us          1                []                                   \n",
      "addmm                    6.02%            7.106us          6.02%            7.106us          7.106us          NaN              0.000us          0.000us          1                []                                   \n",
      "max                      22.09%           26.089us         22.09%           26.089us         26.089us         NaN              0.000us          0.000us          1                []                                   \n",
      "select                   1.97%            2.326us          1.97%            2.326us          2.326us          NaN              0.000us          0.000us          1                []                                   \n",
      "is_floating_point        0.21%            0.251us          0.21%            0.251us          0.251us          NaN              0.000us          0.000us          1                []                                   \n",
      "is_complex               0.22%            0.260us          0.22%            0.260us          0.260us          NaN              0.000us          0.000us          1                []                                   \n",
      "item                     1.62%            1.915us          1.62%            1.915us          1.915us          NaN              0.000us          0.000us          1                []                                   \n",
      "_local_scalar_dense      0.73%            0.861us          0.73%            0.861us          0.861us          NaN              0.000us          0.000us          1                []                                   \n",
      "-----------------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  -----------------------------------  \n",
      "Self CPU time total: 118.110us\n",
      "CUDA time total: 0.000us\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
